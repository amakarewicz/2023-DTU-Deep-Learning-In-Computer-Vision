{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811d6088",
   "metadata": {},
   "source": [
    "### IMPORTANT!\n",
    "Albumentations automatically installs `opencv-python-headless`. To make both augmentations and SelectiveSearch work, you need to uninstall every `opencv` version and install `opencv-contrib-python-headless`.\n",
    "https://stackoverflow.com/questions/57427233/module-cv2-cv2-has-no-attribute-ximgproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408e9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall opencv-python opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba5ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install opencv-contrib-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea91d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from matplotlib.patches import Polygon, Rectangle\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# Own imports \n",
    "from config import * \n",
    "from utils import *\n",
    "from data_loader import TacoDataset\n",
    "\n",
    "# speed-up using multithreads\n",
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68de1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256 # 1024 # AM: changed because it takes too long for SelectiveSearch to run\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.7),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.RGBShift(10, 10, 10, p=0.3),\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Normalize(), # If you want to visualize - comment this line \n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc',\n",
    "                            label_fields=['labels'],\n",
    "                            min_area = 0,\n",
    "                            min_visibility=0.3, # min visibility of the original area in case of a crop\n",
    "                           )\n",
    "    \n",
    ")\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc',\n",
    "                            label_fields=['labels'],\n",
    "                           )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d868c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TacoDataset( 'train', transforms=train_transform, test_size=0.2) # test_transform for no augment\n",
    "valset   = TacoDataset('val', transforms=test_transform, test_size=0.2)\n",
    "testset  = TacoDataset('test', transforms=test_transform, test_size=0.2)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8,collate_fn= lambda x: x)# persistent_workers=True, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8,collate_fn= lambda x: x)# persistent_workers=True, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8,collate_fn= lambda x: x)# persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a298c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_search(img):\n",
    "    \"\"\"\n",
    "    Takes image as an input (np.array not Tensor!)\n",
    "    Returns np.array (number of bboxes x 4)\n",
    "    Bboxes in format x, y, w, h (see demo notebook for example)\n",
    "    \"\"\"\n",
    "    # create selective search segmentation object\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img) \n",
    "    # Choose between fast or accurate selective Search method: fast but low recall V.S. high recall but slow \n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    # AM: Quality takes a looong time, maybe better to try with fast for now and see the results, if bad then change to quality\n",
    "    # ss.switchToSelectiveSearchQuality() \n",
    "    # run selective search\n",
    "    rects = ss.process()\n",
    "    print('Total Number of Region Proposals: {}'.format(len(rects))) # TODO: comment out after making the whole trainset work\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e885bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0535e86ada472f9cbbbdee453bedaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "Total Number of Region Proposals: 360\n",
      "Image 1\n",
      "Total Number of Region Proposals: 408\n",
      "Image 2\n",
      "Total Number of Region Proposals: 928\n",
      "Image 3\n",
      "Total Number of Region Proposals: 994\n",
      "Image 4\n",
      "Total Number of Region Proposals: 474\n",
      "Image 5\n",
      "Total Number of Region Proposals: 1032\n",
      "Image 6\n",
      "Total Number of Region Proposals: 266\n",
      "Image 7\n",
      "Total Number of Region Proposals: 778\n",
      "Image 8\n",
      "Total Number of Region Proposals: 586\n",
      "Image 9\n",
      "Total Number of Region Proposals: 351\n",
      "Image 10\n",
      "Total Number of Region Proposals: 354\n",
      "Image 11\n",
      "Total Number of Region Proposals: 388\n",
      "Image 12\n",
      "Total Number of Region Proposals: 327\n",
      "Image 13\n",
      "Total Number of Region Proposals: 218\n",
      "Image 14\n",
      "Total Number of Region Proposals: 464\n",
      "Image 15\n",
      "Total Number of Region Proposals: 778\n",
      "Image 16\n",
      "Total Number of Region Proposals: 476\n",
      "Image 17\n",
      "Total Number of Region Proposals: 609\n",
      "Image 18\n",
      "Total Number of Region Proposals: 163\n",
      "Image 19\n",
      "Total Number of Region Proposals: 246\n",
      "Image 20\n",
      "Total Number of Region Proposals: 470\n",
      "Image 21\n",
      "Total Number of Region Proposals: 527\n",
      "Image 22\n",
      "Total Number of Region Proposals: 987\n",
      "Image 23\n",
      "Total Number of Region Proposals: 489\n",
      "Image 24\n",
      "Total Number of Region Proposals: 199\n",
      "Image 25\n",
      "Total Number of Region Proposals: 465\n",
      "Image 26\n",
      "Total Number of Region Proposals: 401\n",
      "Image 27\n",
      "Total Number of Region Proposals: 481\n",
      "Image 28\n",
      "Total Number of Region Proposals: 614\n",
      "Image 29\n",
      "Total Number of Region Proposals: 1071\n",
      "Image 30\n",
      "Total Number of Region Proposals: 484\n",
      "Image 31\n",
      "Total Number of Region Proposals: 865\n",
      "Image 32\n",
      "Total Number of Region Proposals: 659\n",
      "Image 33\n",
      "Total Number of Region Proposals: 251\n",
      "Image 34\n",
      "Total Number of Region Proposals: 842\n",
      "Image 35\n",
      "Total Number of Region Proposals: 1047\n",
      "Image 36\n",
      "Total Number of Region Proposals: 114\n",
      "Image 37\n",
      "Total Number of Region Proposals: 948\n",
      "Image 38\n",
      "Total Number of Region Proposals: 195\n",
      "Image 39\n",
      "Total Number of Region Proposals: 356\n",
      "Image 40\n",
      "Total Number of Region Proposals: 992\n",
      "Image 41\n",
      "Total Number of Region Proposals: 899\n",
      "Image 42\n",
      "Total Number of Region Proposals: 1047\n",
      "Image 43\n",
      "Total Number of Region Proposals: 317\n",
      "Image 44\n",
      "Total Number of Region Proposals: 52\n",
      "Image 45\n",
      "Total Number of Region Proposals: 958\n",
      "Image 46\n",
      "Total Number of Region Proposals: 435\n",
      "Image 47\n",
      "Total Number of Region Proposals: 1168\n",
      "Image 48\n",
      "Total Number of Region Proposals: 455\n",
      "Image 49\n",
      "Total Number of Region Proposals: 882\n",
      "Image 50\n",
      "Total Number of Region Proposals: 144\n",
      "Image 51\n",
      "Total Number of Region Proposals: 295\n",
      "Image 52\n",
      "Total Number of Region Proposals: 523\n",
      "Image 53\n",
      "Total Number of Region Proposals: 751\n",
      "Image 54\n",
      "Total Number of Region Proposals: 256\n",
      "Image 55\n",
      "Total Number of Region Proposals: 125\n",
      "Image 56\n",
      "Total Number of Region Proposals: 126\n",
      "Image 57\n",
      "Total Number of Region Proposals: 539\n",
      "Image 58\n",
      "Total Number of Region Proposals: 597\n",
      "Image 59\n",
      "Total Number of Region Proposals: 201\n",
      "Image 60\n",
      "Total Number of Region Proposals: 983\n",
      "Image 61\n",
      "Total Number of Region Proposals: 547\n",
      "Image 62\n",
      "Total Number of Region Proposals: 260\n",
      "Image 63\n",
      "Total Number of Region Proposals: 525\n",
      "Image 64\n",
      "Total Number of Region Proposals: 145\n",
      "Image 65\n",
      "Total Number of Region Proposals: 546\n",
      "Image 66\n",
      "Total Number of Region Proposals: 280\n",
      "Image 67\n",
      "Total Number of Region Proposals: 484\n",
      "Image 68\n",
      "Total Number of Region Proposals: 769\n",
      "Image 69\n",
      "Total Number of Region Proposals: 430\n",
      "Image 70\n",
      "Total Number of Region Proposals: 312\n",
      "Image 71\n",
      "Total Number of Region Proposals: 408\n",
      "Image 72\n",
      "Total Number of Region Proposals: 228\n",
      "Image 73\n",
      "Total Number of Region Proposals: 585\n",
      "Image 74\n",
      "Total Number of Region Proposals: 326\n",
      "Image 75\n",
      "Total Number of Region Proposals: 1005\n",
      "Image 76\n",
      "Total Number of Region Proposals: 863\n",
      "Image 77\n",
      "Total Number of Region Proposals: 365\n",
      "Image 78\n",
      "Total Number of Region Proposals: 676\n",
      "Image 79\n",
      "Total Number of Region Proposals: 533\n",
      "Image 80\n",
      "Total Number of Region Proposals: 410\n",
      "Image 81\n",
      "Total Number of Region Proposals: 323\n",
      "Image 82\n",
      "Total Number of Region Proposals: 505\n",
      "Image 83\n",
      "Total Number of Region Proposals: 342\n",
      "Image 84\n",
      "Total Number of Region Proposals: 937\n",
      "Image 85\n",
      "Total Number of Region Proposals: 674\n",
      "Image 86\n",
      "Total Number of Region Proposals: 695\n",
      "Image 87\n",
      "Total Number of Region Proposals: 307\n",
      "Image 88\n",
      "Total Number of Region Proposals: 1034\n",
      "Image 89\n",
      "Total Number of Region Proposals: 210\n",
      "Image 90\n",
      "Total Number of Region Proposals: 563\n",
      "Image 91\n",
      "Total Number of Region Proposals: 530\n",
      "Image 92\n",
      "Total Number of Region Proposals: 359\n",
      "Image 93\n",
      "Total Number of Region Proposals: 947\n",
      "Image 94\n",
      "Total Number of Region Proposals: 321\n",
      "Image 95\n",
      "Total Number of Region Proposals: 828\n",
      "Image 96\n",
      "Total Number of Region Proposals: 84\n",
      "Image 97\n",
      "Total Number of Region Proposals: 330\n",
      "Image 98\n",
      "Total Number of Region Proposals: 637\n",
      "Image 99\n",
      "Total Number of Region Proposals: 196\n",
      "Image 100\n",
      "Total Number of Region Proposals: 308\n",
      "Image 101\n",
      "Total Number of Region Proposals: 849\n",
      "Image 102\n",
      "Total Number of Region Proposals: 213\n",
      "Image 103\n",
      "Total Number of Region Proposals: 523\n",
      "Image 104\n",
      "Total Number of Region Proposals: 626\n",
      "Image 105\n",
      "Total Number of Region Proposals: 830\n",
      "Image 106\n",
      "Total Number of Region Proposals: 787\n",
      "Image 107\n",
      "Total Number of Region Proposals: 661\n",
      "Image 108\n",
      "Total Number of Region Proposals: 321\n",
      "Image 109\n",
      "Total Number of Region Proposals: 405\n",
      "Image 110\n",
      "Total Number of Region Proposals: 607\n",
      "Image 111\n",
      "Total Number of Region Proposals: 754\n",
      "Image 112\n",
      "Total Number of Region Proposals: 600\n",
      "Image 113\n",
      "Total Number of Region Proposals: 489\n",
      "Image 114\n",
      "Total Number of Region Proposals: 122\n",
      "Image 115\n",
      "Total Number of Region Proposals: 777\n",
      "Image 116\n",
      "Total Number of Region Proposals: 326\n",
      "Image 117\n",
      "Total Number of Region Proposals: 498\n",
      "Image 118\n",
      "Total Number of Region Proposals: 966\n",
      "Image 119\n",
      "Total Number of Region Proposals: 172\n",
      "Image 120\n",
      "Total Number of Region Proposals: 1148\n",
      "Image 121\n",
      "Total Number of Region Proposals: 592\n",
      "Image 122\n",
      "Total Number of Region Proposals: 356\n",
      "Image 123\n",
      "Total Number of Region Proposals: 572\n",
      "Image 124\n",
      "Total Number of Region Proposals: 744\n",
      "Image 125\n",
      "Total Number of Region Proposals: 891\n",
      "Image 126\n",
      "Total Number of Region Proposals: 703\n",
      "Image 127\n",
      "Total Number of Region Proposals: 519\n",
      "Image 128\n",
      "Total Number of Region Proposals: 505\n",
      "Image 129\n",
      "Total Number of Region Proposals: 737\n",
      "Image 130\n",
      "Total Number of Region Proposals: 751\n",
      "Image 131\n",
      "Total Number of Region Proposals: 649\n",
      "Image 132\n",
      "Total Number of Region Proposals: 346\n",
      "Image 133\n",
      "Total Number of Region Proposals: 452\n",
      "Image 134\n",
      "Total Number of Region Proposals: 997\n",
      "Image 135\n",
      "Total Number of Region Proposals: 1152\n",
      "Image 136\n",
      "Total Number of Region Proposals: 567\n",
      "Image 137\n",
      "Total Number of Region Proposals: 583\n",
      "Image 138\n",
      "Total Number of Region Proposals: 773\n",
      "Image 139\n",
      "Total Number of Region Proposals: 264\n",
      "Image 140\n",
      "Total Number of Region Proposals: 526\n",
      "Image 141\n",
      "Total Number of Region Proposals: 786\n",
      "Image 142\n",
      "Total Number of Region Proposals: 182\n",
      "Image 143\n",
      "Total Number of Region Proposals: 539\n",
      "Image 144\n",
      "Total Number of Region Proposals: 595\n",
      "Image 145\n",
      "Total Number of Region Proposals: 240\n",
      "Image 146\n",
      "Total Number of Region Proposals: 629\n",
      "Image 147\n",
      "Total Number of Region Proposals: 421\n",
      "Image 148\n",
      "Total Number of Region Proposals: 473\n",
      "Image 149\n",
      "Total Number of Region Proposals: 1046\n",
      "Image 150\n",
      "Total Number of Region Proposals: 556\n",
      "Image 151\n",
      "Total Number of Region Proposals: 830\n",
      "Image 152\n",
      "Total Number of Region Proposals: 852\n",
      "Image 153\n",
      "Total Number of Region Proposals: 1112\n",
      "Image 154\n",
      "Total Number of Region Proposals: 507\n",
      "Image 155\n",
      "Total Number of Region Proposals: 525\n",
      "Image 156\n",
      "Total Number of Region Proposals: 799\n",
      "Image 157\n",
      "Total Number of Region Proposals: 235\n",
      "Image 158\n",
      "Total Number of Region Proposals: 348\n",
      "Image 159\n",
      "Total Number of Region Proposals: 423\n",
      "Image 160\n",
      "Total Number of Region Proposals: 807\n",
      "Image 161\n",
      "Total Number of Region Proposals: 521\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected y_min for bbox (tensor(0.), tensor(-0.0003), tensor(0.7412), tensor(0.5907), tensor(1)) to be in the range [0.0, 1.0], got -0.0002500000118743628.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_proposals \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (img, _, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(trainset)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     proposals \u001b[38;5;241m=\u001b[39m selective_search(img\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DLiCV/Project1/2023-DTU-Deep-Learning-In-Computer-Vision/IV-Object-Detection/data_loader.py:138\u001b[0m, in \u001b[0;36mTacoDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    135\u001b[0m target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miscrowd\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m iscrowd\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/composition.py:207\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    202\u001b[0m check_each_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(item\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_each_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 207\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transforms):\n\u001b[1;32m    210\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/utils.py:83\u001b[0m, in \u001b[0;36mDataProcessor.preprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     81\u001b[0m rows, cols \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fields:\n\u001b[0;32m---> 83\u001b[0m     data[data_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/utils.py:91\u001b[0m, in \u001b[0;36mDataProcessor.check_and_convert\u001b[0;34m(self, data, rows, cols, direction)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_albumentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_from_albumentations(data, rows, cols)\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/bbox_utils.py:142\u001b[0m, in \u001b[0;36mBboxProcessor.convert_to_albumentations\u001b[0;34m(self, data, rows, cols)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_albumentations\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Sequence[BoxType], rows: \u001b[38;5;28mint\u001b[39m, cols: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BoxType]:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_bboxes_to_albumentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_validity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/bbox_utils.py:408\u001b[0m, in \u001b[0;36mconvert_bboxes_to_albumentations\u001b[0;34m(bboxes, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_bboxes_to_albumentations\u001b[39m(\n\u001b[1;32m    405\u001b[0m     bboxes: Sequence[BoxType], source_format, rows, cols, check_validity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BoxType]:\n\u001b[1;32m    407\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes]\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/bbox_utils.py:408\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_bboxes_to_albumentations\u001b[39m(\n\u001b[1;32m    405\u001b[0m     bboxes: Sequence[BoxType], source_format, rows, cols, check_validity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BoxType]:\n\u001b[1;32m    407\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mconvert_bbox_to_albumentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_validity\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes]\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/bbox_utils.py:352\u001b[0m, in \u001b[0;36mconvert_bbox_to_albumentations\u001b[0;34m(bbox, source_format, rows, cols, check_validity)\u001b[0m\n\u001b[1;32m    350\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m normalize_bbox(bbox, rows, cols)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_validity:\n\u001b[0;32m--> 352\u001b[0m     \u001b[43mcheck_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
      "File \u001b[0;32m~/Desktop/venv_1/lib/python3.10/site-packages/albumentations/core/bbox_utils.py:435\u001b[0m, in \u001b[0;36mcheck_bbox\u001b[0;34m(bbox)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_max\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_max\u001b[39m\u001b[38;5;124m\"\u001b[39m], bbox[:\u001b[38;5;241m4\u001b[39m]):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(value, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(value, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for bbox \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to be in the range [0.0, 1.0], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    436\u001b[0m x_min, y_min, x_max, y_max \u001b[38;5;241m=\u001b[39m bbox[:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_max \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m x_min:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected y_min for bbox (tensor(0.), tensor(-0.0003), tensor(0.7412), tensor(0.5907), tensor(1)) to be in the range [0.0, 1.0], got -0.0002500000118743628."
     ]
    }
   ],
   "source": [
    "train_proposals = []\n",
    "for i, (img, _, _) in enumerate(tqdm(trainset)):\n",
    "    print(f\"Image {i}\")\n",
    "    proposals = selective_search(img.permute([1,2,0]).numpy())\n",
    "    train_proposals.append(proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for last working img from trainset)\n",
    "\n",
    "# number of region proposals to show\n",
    "numShowRects = 70\n",
    "\n",
    "# create a copy of original image\n",
    "imOut = img.permute([1,2,0]).numpy().copy()\n",
    "\n",
    "# itereate over all the region proposals\n",
    "for i, rect in enumerate(proposals):\n",
    "    # draw rectangle for region proposal till numShowRects\n",
    "    if (i < numShowRects):\n",
    "        x, y, w, h = rect\n",
    "        color = list(np.random.random(size=3) * 256)\n",
    "        cv2.rectangle(imOut, (x, y), (x+w, y+h), color, 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "plt.imshow(imOut[...,::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

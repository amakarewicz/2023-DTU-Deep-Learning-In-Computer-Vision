{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJGZfGf3NN-u"
   },
   "source": [
    "## FFHQ Face Image Alignment\n",
    "\n",
    "- [`Happy-jihye`](https://github.com/happy-jihye)\n",
    "- **landmark detector** : [`1adrianb/face-alignment`](https://github.com/1adrianb/face-alignment)\n",
    "  - `pip install face-alignment`\n",
    "- **FFHQ alignment** : [NVlabs/ffhq-dataset](https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-alignment\n",
      "  Downloading face_alignment-1.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: torch in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from face-alignment) (2.0.1+cu118)\n",
      "Requirement already satisfied: numpy in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from face-alignment) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.17 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from face-alignment) (1.10.1)\n",
      "Requirement already satisfied: scikit-image in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from face-alignment) (0.21.0)\n",
      "Collecting opencv-python (from face-alignment)\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from face-alignment) (4.65.0)\n",
      "Collecting numba (from face-alignment)\n",
      "  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.41,>=0.40.0dev0 (from numba->face-alignment)\n",
      "  Downloading llvmlite-0.40.1rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (3.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (2.31.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from scikit-image->face-alignment) (0.2)\n",
      "Requirement already satisfied: filelock in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from torch->face-alignment) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from torch->face-alignment) (4.4.0)\n",
      "Requirement already satisfied: sympy in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from torch->face-alignment) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from torch->face-alignment) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from torch->face-alignment) (2.0.0)\n",
      "Requirement already satisfied: cmake in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from triton==2.0.0->torch->face-alignment) (3.25.0)\n",
      "Requirement already satisfied: lit in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from triton==2.0.0->torch->face-alignment) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from jinja2->torch->face-alignment) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /zhome/7c/2/136917/Desktop/venv_1/lib/python3.10/site-packages (from sympy->torch->face-alignment) (1.2.1)\n",
      "Installing collected packages: opencv-python, llvmlite, numba, face-alignment\n",
      "Successfully installed face-alignment-1.4.0 llvmlite-0.40.1rc1 numba-0.57.0 opencv-python-4.7.0.72\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install face-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import PIL.Image\n",
    "import face_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AJuy-B5kEGiK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def image_align(src_file, dst_file, face_landmarks, output_size=256, transform_size=1024, enable_padding=True):\n",
    "        # Align function from FFHQ dataset pre-processing step\n",
    "        # https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\n",
    "\n",
    "        lm = np.array(face_landmarks)\n",
    "        lm_chin          = lm[0  : 17, :2]  # left-right\n",
    "        lm_eyebrow_left  = lm[17 : 22, :2]  # left-right\n",
    "        lm_eyebrow_right = lm[22 : 27, :2]  # left-right\n",
    "        lm_nose          = lm[27 : 31, :2]  # top-down\n",
    "        lm_nostrils      = lm[31 : 36, :2]  # top-down\n",
    "        lm_eye_left      = lm[36 : 42, :2]  # left-clockwise\n",
    "        lm_eye_right     = lm[42 : 48, :2]  # left-clockwise\n",
    "        lm_mouth_outer   = lm[48 : 60, :2]  # left-clockwise\n",
    "        lm_mouth_inner   = lm[60 : 68, :2]  # left-clockwise\n",
    "\n",
    "        # Calculate auxiliary vectors.\n",
    "        eye_left     = np.mean(lm_eye_left, axis=0)\n",
    "        eye_right    = np.mean(lm_eye_right, axis=0)\n",
    "        eye_avg      = (eye_left + eye_right) * 0.5\n",
    "        eye_to_eye   = eye_right - eye_left\n",
    "        mouth_left   = lm_mouth_outer[0]\n",
    "        mouth_right  = lm_mouth_outer[6]\n",
    "        mouth_avg    = (mouth_left + mouth_right) * 0.5\n",
    "        eye_to_mouth = mouth_avg - eye_avg\n",
    "\n",
    "        # Choose oriented crop rectangle.\n",
    "        x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
    "        x /= np.hypot(*x)\n",
    "        x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "        y = np.flipud(x) * [-1, 1]\n",
    "        c = eye_avg + eye_to_mouth * 0.1\n",
    "        quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "        qsize = np.hypot(*x) * 2\n",
    "\n",
    "        # Load in-the-wild image.\n",
    "        if not os.path.isfile(src_file):\n",
    "            print('\\nCannot find source image. Please run \"--wilds\" before \"--align\".')\n",
    "            return\n",
    "        img = PIL.Image.open(src_file)\n",
    "\n",
    "        # Shrink.\n",
    "        shrink = int(np.floor(qsize / output_size * 0.5))\n",
    "        if shrink > 1:\n",
    "            rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
    "            img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
    "            quad /= shrink\n",
    "            qsize /= shrink\n",
    "\n",
    "        # Crop.\n",
    "        border = max(int(np.rint(qsize * 0.1)), 3)\n",
    "        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
    "        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
    "            img = img.crop(crop)\n",
    "            quad -= crop[0:2]\n",
    "\n",
    "        # Pad.\n",
    "        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
    "        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
    "        if enable_padding and max(pad) > border - 4:\n",
    "            pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
    "            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "            h, w, _ = img.shape\n",
    "            y, x, _ = np.ogrid[:h, :w, :1]\n",
    "            mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\n",
    "            blur = qsize * 0.02\n",
    "            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "            img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
    "            quad += pad[:2]\n",
    "\n",
    "        # Transform.\n",
    "        img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
    "        if output_size < transform_size:\n",
    "            img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "        # Save aligned image.\n",
    "        img.save(dst_file, 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M-j-59NNuh1"
   },
   "source": [
    "### <b>Image Alignment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75588/1907232987.py:75: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
      "/tmp/ipykernel_75588/1907232987.py:45: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize(rsize, PIL.Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RAW_IMAGES_DIR = './raw_images'\n",
    "ALIGNED_IMAGES_DIR = './aligned_images'\n",
    "\n",
    "if not os.path.exists(ALIGNED_IMAGES_DIR):\n",
    "    os.makedirs(ALIGNED_IMAGES_DIR)\n",
    "\n",
    "landmarks_detector = face_alignment.FaceAlignment(face_alignment.LandmarksType.THREE_D, flip_input=False)\n",
    "\n",
    "for img_name in os.listdir(RAW_IMAGES_DIR):\n",
    "    raw_img_path = os.path.join(RAW_IMAGES_DIR, img_name)\n",
    "\n",
    "    for i, face_landmarks in enumerate(landmarks_detector.get_landmarks(raw_img_path), start=1):\n",
    " \n",
    "        aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, f'align-{img_name}')\n",
    "\n",
    "        image_align(raw_img_path, aligned_face_path, face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPWWhR+nzwazNEMYQ629vkX",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Face Image Alignment",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

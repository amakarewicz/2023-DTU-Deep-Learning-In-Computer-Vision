{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae267c0a-15a1-4a58-8f81-940199ca460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f3f40-7976-4b1e-ac70-ca2dfcb7cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "\n",
    "# pip install torchsummary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import torchmetrics\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563c36b-32f0-4655-bdbc-3245bbaa6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ! pip install opencv-python==4.5.5.64\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f2b29-83a6-41e5-b946-b8383103c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df732e08-ccab-4905-97ca-250b729d4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c205faf-e118-4f6e-a649-477aed2c49a4",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d9532-8d6e-4687-9ff2-46a6fdc24f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_img_and_label():\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(5):\n",
    "        im, lb = trainset.__getitem__(i)\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(im.permute(1,2,0))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplot(2, 5, 6+i)\n",
    "        plt.imshow(lb) # lab.permute(1,2,0)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b248e-4bb5-4419-8f57-4ff1f3ce7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import PH2, DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5654d2-9844-4d72-9cc6-982ae197a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(size, size),\n",
    "        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose([A.Resize(size, size), \n",
    "                            A.Normalize(),\n",
    "                            ToTensorV2()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cbced-ccba-46a6-8afc-0f4e6cd68d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = PH2('train', transform=train_transform)\n",
    "valset = PH2('val', transform=test_transform)\n",
    "testset = PH2('test', transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8,)# persistent_workers=True, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=8,)# persistent_workers=True, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=8,)# persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aee5e6-1d66-4cf5-b7c5-b723f5ecef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_img_and_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba550a-6eb0-4751-988c-45e7d52dcb94",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47aa64-62cf-48e1-b34b-ff23650f77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.first_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "                \n",
    "        self.middle_layer = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.concat_layer = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.end_layer = nn.Sequential(\n",
    "            nn.Conv2d(128, 1, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x0 = self.first_layer(x)\n",
    "        x = self.middle_layer(x0)\n",
    "        x = self.middle_layer(x)\n",
    "        x = self.middle_layer(x)\n",
    "\n",
    "        x = torch.concat([x, x0], 1)\n",
    "        x1 = self.concat_layer(x)\n",
    "        x = self.middle_layer(x1)\n",
    "        x = self.middle_layer(x)\n",
    "        \n",
    "        x = torch.concat([x, x1], 1)\n",
    "        x2 = self.concat_layer(x)\n",
    "        x = self.middle_layer(x2)\n",
    "        x = self.middle_layer(x)\n",
    "\n",
    "        \n",
    "        x = torch.concat([x, x1], 1)\n",
    "        x = self.end_layer(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1510ad-2b98-4473-b77f-2ea7d6b6de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncDec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.enc_conv1 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.enc_conv3 = nn.Conv2d(64, 1, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e0 = F.relu(self.enc_conv0(x))\n",
    "        e1 = F.relu(self.enc_conv1(e0))\n",
    "        e2 = F.relu(self.enc_conv2(e1))\n",
    "\n",
    "        # no activation\n",
    "        e3 = self.enc_conv3(e2)\n",
    "        \n",
    "        return e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd69d7d-8401-4c21-a43c-28a03f17642b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {
    "08561c3a-f5c9-460e-9ad3-5c4b1b078115.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a5ffe279-3444-4653-9429-8429a29ad275",
   "metadata": {},
   "source": [
    "![image.png](attachment:08561c3a-f5c9-460e-9ad3-5c4b1b078115.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51a0d6-affb-4e38-b74a-203754ef5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Metric\n",
    "\n",
    "class Sensitivity(Metric):\n",
    "    def __init__(self, num_classes=2, threshold=0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"true_positives\", default=torch.zeros(num_classes), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"false_negatives\", default=torch.zeros(num_classes), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds, target):\n",
    "        preds = (preds >= self.threshold).int()\n",
    "        target = target.int()\n",
    "\n",
    "        true_positives = torch.sum(preds * target, dim=0)\n",
    "        false_negatives = torch.sum(target * (1 - preds), dim=0)\n",
    "\n",
    "        self.true_positives += true_positives\n",
    "        self.false_negatives += false_negatives\n",
    "\n",
    "    def compute(self):\n",
    "        sensitivity = self.true_positives / (self.true_positives + self.false_negatives + 1e-8)\n",
    "        return sensitivity\n",
    "\n",
    "    def reset(self):\n",
    "        self.true_positives.zero_()\n",
    "        self.false_negatives.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daee691-5374-4277-b498-ae39b927a5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3f2d0-52a1-4b1b-b6b5-21b27e0c92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, train_loader, val_loader, test_loader):\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "\n",
    "    metric_dict = {\n",
    "                'train_dice': torchmetrics.Dice().to(device),\n",
    "                'train_iou': torchmetrics.JaccardIndex('binary').to(device),\n",
    "                'train_acc': torchmetrics.Accuracy('binary').to(device),\n",
    "                'train_sens': Sensitivity().to(device),\n",
    "                'train_spec': torchmetrics.Specificity('binary').to(device),\n",
    "                \n",
    "                'val_dice': torchmetrics.Dice().to(device),\n",
    "                'val_iou': torchmetrics.JaccardIndex('binary').to(device),\n",
    "                'val_acc': torchmetrics.Accuracy('binary').to(device),\n",
    "                'val_sens': Sensitivity().to(device),\n",
    "                'val_spec': torchmetrics.Specificity('binary').to(device),\n",
    "\n",
    "                                \n",
    "                'test_dice': torchmetrics.Dice().to(device),\n",
    "                'test_iou': torchmetrics.JaccardIndex('binary').to(device),\n",
    "                'test_acc': torchmetrics.Accuracy('binary').to(device),\n",
    "                'test_sens': Sensitivity().to(device),\n",
    "                'test_spec': torchmetrics.Specificity('binary').to(device),\n",
    "               }\n",
    "\n",
    "    out_dict = {\n",
    "                \n",
    "                'train_loss':[],\n",
    "                'train_dice': [],\n",
    "                'train_iou': [],\n",
    "                'train_acc': [],\n",
    "                'train_sens': [],\n",
    "                'train_spec': [],\n",
    "\n",
    "                'val_loss':[],\n",
    "                'val_dice': [],\n",
    "                'val_iou':[],\n",
    "                'val_acc': [],\n",
    "                'val_sens': [],\n",
    "                'val_spec': [],\n",
    "\n",
    "                                \n",
    "                'test_dice': [],\n",
    "                'test_iou': [],\n",
    "                'test_acc': [],\n",
    "                'test_sens': [],\n",
    "                'test_spec': [],\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        \n",
    "        avg_loss = 0\n",
    "        avg_loss_val = 0\n",
    "        \n",
    "        model.train()  # train mode\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            Y_batch = Y_batch.unsqueeze(1)\n",
    "            loss = loss_fn(Y_pred, Y_batch)  # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            avg_loss += loss / len(train_loader)\n",
    "\n",
    "            metric_dict['train_dice'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['train_acc'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['train_iou'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['train_sens'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['train_spec'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "\n",
    "            \n",
    "        toc = time()\n",
    "\n",
    "        model.eval()  # testing mode\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            \n",
    "            Y_pred = model(X_batch)\n",
    "            Y_batch = Y_batch.unsqueeze(1)\n",
    "            loss_test = loss_fn(Y_pred, Y_batch)  # forward-pass\n",
    "            avg_loss_val += loss / len(val_loader)\n",
    "\n",
    "            metric_dict['val_dice'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['val_acc'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['val_iou'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['val_sens'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            metric_dict['val_spec'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "            \n",
    "        \n",
    "        train_loss.append(avg_loss.detach().cpu())\n",
    "        val_loss.append(avg_loss_val.detach().cpu())\n",
    "\n",
    "        #plt.plot(train_loss, np.arange(len(train_loss)))\n",
    "        #plt.plot(test_loss, np.arange(len(test_loss)))\n",
    "                 \n",
    "        for metric in ['dice', 'acc', 'iou', 'sens', 'spec']:\n",
    "            out_dict['train_' + metric].append(metric_dict['train_' + metric].compute().detach().cpu())\n",
    "            out_dict['val_' + metric].append(metric_dict['val_' + metric].compute().detach().cpu())\n",
    "\n",
    "        \n",
    "        print(f\"Loss train: {avg_loss:.3f}\\t Val Acc: {metric_dict['val_acc'].compute():.3f}\\t, Val Dice: {metric_dict['val_dice'].compute()}\")\n",
    "\n",
    "    model.eval()  # testing mode\n",
    "    for X_batch, Y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        \n",
    "        Y_pred = model(X_batch)\n",
    "        Y_batch = Y_batch.unsqueeze(1)\n",
    "\n",
    "        metric_dict['test_dice'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "        metric_dict['test_acc'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "        metric_dict['test_iou'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "        metric_dict['test_sens'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "        metric_dict['test_spec'](F.sigmoid(Y_pred.flatten()), Y_batch.flatten().to(int))\n",
    "\n",
    "    for metric in ['dice', 'acc', 'iou', 'sens', 'spec']:\n",
    "        out_dict['test_' + metric].append(metric_dict['test_' + metric].compute().detach().cpu())\n",
    "\n",
    "    out_dict['train_loss'] = [train_loss]\n",
    "    out_dict['val_loss'] = [val_loss]\n",
    "    \n",
    "    \n",
    "    return out_dict, metric_dict\n",
    "\n",
    "\n",
    "    \n",
    "def predict(model, data):\n",
    "    model.eval()  # testing mode\n",
    "    Y_pred = [F.sigmoid(model(X_batch.to(device))) for X_batch, _ in data]\n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7ce23-3cc9-452e-827d-05ed4db399bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncDec().to(device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02afb6-4943-4215-b334-c6f72abceee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict, metric_dict = train(model, optim.Adam(model.parameters(), 0.0001), loss_fn, 50, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b82896-5ddc-4b32-8105-0b289f032b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
